---
title: python网络爬虫
author: lonelywatch
date: 2023-7-13 15:45 +0800
categories: [PYTHON]
tags: [PYTHON,WEB,爬虫]
---

## 烦人的东西

因为python课设要用到很多没学过的东西，所以只好先暂停编译，先来弄这个，虽然这个也挺有意思的，但是被强迫学习还是有点讨厌。

## 数据的存储

### CSV

爬虫需要将数据以一定方式进行存储，一种简单的方式是通过CSV(逗号分隔符)。该类型的文件内容将每行一个个数据以逗号分割，有若干行。通过python的csv库可以对csv文件进行相应操作。

```python
import csv

# 读csv文件
with open('example.csv', 'r') as file:
    # 创建读取器
    reader = csv.reader(file)
    for row in reader:
        print(row)
with open('example.csv', 'w') as file:
    writer = csv.writer(file)
    for xx in xxx:
        writer.writerow(xx,newline='')
```

通过创建读写器来进行读写，`writerow`写1行数据，`writerows`写多行数据，但数据必须是可迭代对象，`newline=''`避免产生空行。

### 数据库

数据库用于存储大量数据，这里我使用开源免费的MYSQL，通过python中的PyMySQL库可以将python与MYSQL交互。MYSQL的安装及操作参考菜鸟教程。

通过连接到数据库来使用数据库，一个连接可以创建若干个光标，光标用于对数据库的操作。

```python
import pymysql

## 创建连接
with pymysql.connect(host='127.0.0.1', user='root',
                     password='ilikeyou2003', database='mysql') as conn:
    # 创建一个光标
    with conn.cursor() as cursor:
        cursor = conn.cursor()
        sql = 'SELECT * FROM user;'
        #执行语句
        cursor.execute(sql)
        #取得所有结果
        result = cursor.fetchall()

        for row in result:
            print(row)

```

## 爬虫

在python中可以使用urllib来进行url相关的操作，最常见的就是打开url`urlopen`(位于request子模块中)。同样`unquote`（parse子模块）可以将URL编码解码等等。re为python中的正则表达式库。BeautifulSoup是一个xml和html的解析器，bs4为它在python中的库。所谓爬虫，大致就是解析网页，在互联网的链接中爬取信息。