---
title: 操作系统
author: lonelywatch
date: 2024-06-05 21:28 +0800
categories: [OS]
tags: [OS]   
---


# 操作系统

操作系统可以被理解为特殊的应用程序，是用户与计算机硬件系统之间的接口。操作系统的主要功能是管理计算机系统的硬件资源，提供用户与计算机硬件系统之间的接口，为用户提供一个方便、安全、高效的工作环境。

## 引导

## 线程与进程

进程与线程都是对执行任务的抽象，只是其聚焦点不同。

### 进程

在进程模型中，所有计算机上可运行的软件，被组织成若干进程。**进程就是正在执行程序的实例**，除了程序本身的代码与数据外，其拥有若干资源，包括寄存器，内存，文件，CPU等（这当然也可以理解为对进程某一时刻状态的抽象，或者说是**上下文**，用于实现若干进程在同一CPU上运行）。

进程拥有一定空间的状态，通常包括： 就绪，运行，阻塞，终止。或者也可以将终止删除。 对于使用某些资源频繁的进程，通常可分为 CPU密集型和IO密集型进程。对于IO密集型进程，进程数量的增长往往能够很好地提高CPU利用率。

操作系统为了管理进程，通常会在内核中存放一张进程表，其中每一项都是一个进程控制块（PCB），用于存放进程的信息，包括进程的状态，进程ID，进程的优先级，进程的寄存器，进程的内存分配，进程的文件描述符等，也就是之前提到的进程上下文。

### 线程

线程具有进程的某些特征，是建立在进程上的新抽象。进程拥有若干线程，线程能够共享进程的地址空间进而共享可用数据，因而比进程更为轻量。



### IPC通信

### 调度

调度就是选择某一任务执行。这一过程通常发生在：

1. 某任务退出时
2. 创建新任务时
3. 任务被阻塞时
4. IO中断发生时

调度算法对于不同环境有不同的要求，大致可分为三类环境，分别为： 批处理，交互时，实时。 

批处理通常处理大量周期性的任务，适合非抢占算法或者长时间周期的抢占式算法，尽可能提高系统的吞吐量和CPU利用率，并且降低CPU周转时间；

- 周转时间： 一批处理作业提交时刻到完成为止地统计平均时间

交互式通常需要抢占式算法来提供良好的响应速度和均衡性。 

实时环境比较特殊，或多或少使得每一任务满足截止时间，并且任务的执行时间往往可预测。

除了每一类环境特定要求外，调度算法还应尽可能地满足 公平，系统策略强制执行以及高资源利用率等要求。

#### 批处理

##### 先来先服务（FCFS）

非抢占式算法的一种。任务按照其请求CPU的顺序来使用CPU。任务运行时不会受到中断，直到任务阻塞时，就会切换到其队列中位于该任务之后的任务执行；当任务从阻塞中恢复就绪时，就会被放到队列的尾部。

##### 短作业优先（SJF）

非抢占式算法的一种。该算法假设所有的任务执行时间已知，每次选择执行时间最短的任务。

##### 最短剩余时间优先（SRTF）

短作业优先的抢占式版本。调度程序总是选择剩余时间最短的任务执行。

#### 交互式

##### 轮转 (RR)

抢占式算法的一种。每个任务被分配一个时间片，当时间片用完时，任务被放到队列的尾部，然后调度下一个任务;如果任务提前结束或阻塞，就切换任务并将该任务移出队列或者放到队列的尾部。

需要注意轮转算法的时间片，时间片过大会导致任务响应时间过长，时间片过小会导致任务切换过于频繁。

##### 优先级调度 (PS)

抢占式算法的一种，每一任务具有某一优先级，优先级最高的可运行任务先运行。为了防止高优先级进程一直运行，调度程序可以在每次时钟中断时降低当前进程的优先级，如果存在更高优先级的进程，就进行进程切换。 一种实现为：对于每一优先级拥有一个任务队列，每个队列使用轮转算法，同时实现之前的优先级变换。

##### 多级队列调度 (MLQ)

多级队列调度是一种综合了轮转和优先级调度的算法。将任务分为多个队列，每个队列使用不同的调度算法，例如：高优先级队列使用轮转算法，低优先级队列使用优先级调度算法。当一个任务进入系统时，首先进入高优先级队列，当高优先级队列为空时，才会进入低优先级队列。

##### 彩票调度 (LOTTERY)

彩票调度是一种随机调度算法，每个任务被分配一定数量的彩票，调度程序在每次时钟中断时，从所有彩票中随机选择一个任务执行。这种算法可以实现公平性，但是可能会导致任务的响应时间不稳定。

#### 实时环境

实时环境通常可分为硬实时与软实时。硬实时要求任务必须在截止时间前完成，而软实时则要求任务尽量在截止时间前完成，但是允许一定的延迟。

实时环境中的事件通常可分为周期性与非周期性。对于周期性事件，只有当每一事件处理时间与对应周期之比 的总和小于等于1时，该系统才是可调度的（建立在上下文切换代价忽略不计的前提下）。

#### 进程与线程

进程与线程的调度是两个层级，并且线程的调度方式往往取决于其是否是内核线程。内核线程是由操作系统管理的线程，而用户线程则是由用户库管理的线程。对于用户线程，内核的调度程序并不知道线程的存在，所以按照之前所说对进程进行调度。 进程下的所有线程由该进程的线程调度程序进行调度；对于内核线程，内核调度的对象其实是线程，在调度时，选择某一线程进行调度（通常并不选择特定的进程下的线程）。

内核线程与用户级线程区别在于：

1. 内核线程切换时需要类似于进程切换的开销，而用户级线程并不需要

2. 内核级线程在IO阻塞时不会阻塞整个进程，而用户级线程会

3. 内核级线程可以利用多核，而用户级线程不行


## 存储管理



## 并发与锁

## 文件系统

## IO与设备管理

IO涉及到硬件相关，从软件的角度则只需考虑其提供给底层软件的接口与返回数据。IO设备可分为块设备与字符设备，块设备将信息存储于固定大小的且具有地址的块且传输以若干连续块作为单位，其基本特征为每个块独立于其他块读写。字符设备以字符为单位读写字节流，且不可寻址。

### 设备控制器

IO设备一般由机械部件与电子部件两部分组成，其中电子部件被称为设备控制器。控制器负责将机械部件传入的穿行位流转化为字节块，并进行必要的错误检查。

### 内存映射IO

IO控制器通常提供若干寄存器与CPU通信，除此以外某些设备还提供OS可读写的数据缓冲区，比如GPU等。
就具体的CPU与IO通信而言，总共有2种方式，第一种是通过IO空间，将控制寄存器分配一个IO端口号，CPU通过IO指令读写该IO端口，这就使得存在两类地址空间，分别为内存空间与IO空间。第二种则是将控制寄存器映射到内存空间，并被分配内存地址，被称为内存映射IO。

基于上面的软件角度的通信方式，回到硬件角度，如果CPU需要读写一个字，其都需要将对应地址放入对应总线的地址线上，然后在总线的控制线上置起READ或WRITE信号，并且如果是IO端口，则还需要第二条信号线表示是否为IO空间。对于给定的地址，每个内存模块与IO设备都会将其与自身的地址范围比较，如果匹配则会响应该请求。

内存映射IO较端口映射IO相比，可以使用普通的内存读写指令，并且可以利用页表等管理机制，动态地控制访问权限。但是内存映射IO涉及到Cache，具体而言则是在通过MMIO读取第一次数据后，后续的值可能会被Cache命中，而不会再次读取，这需要硬件能够为页面选择性禁用Cache的能力。除此以外还需要考虑多总线，这时IO往往不能与内存共享总线，好的设计是，在PCI桥芯片中对地址进行过滤，对对应地址范围进行标志并匹配。

### DMA

直接内存访问，是一种硬件技术，用于减少CPU与IO设备之间的通信。DMA控制器负责将数据从IO设备传输到内存，或者从内存传输到IO设备，而不需要CPU的干预。DMA控制器通过总线与CPU通信，CPU通过DMA控制器配置DMA操作，然后DMA控制器负责执行。

![](https://lonelywatch-1306651324.cos.ap-beijing.myqcloud.com/image-20240914174219500.png)

和普通的CPU进行IO相比，DMA在被CPU通过DMA的控制寄存器设计后，知道对应数据与对应的传送位置，所以读写操作发出由DMA负责，CPU只需要处理DMA完成后发出的中断。

### 中断

对于IO设备需要产生终端的情况，其具体工作方式为 **在总线分配给他的信号线上置位信号**。该信号会被主板上的中断控制器芯片检测。

![](https://lonelywatch-1306651324.cos.ap-beijing.myqcloud.com/image-20240914174600600.png)


### 磁盘

磁盘被组织为扇区-磁道-柱面的结构，通过磁头来读写数据。RAID是一种磁盘阵列技术，通过将多个磁盘组合在一起，提高磁盘的性能与容错性。RAID具有0级到5级多种模式，


## 多处理机

多处理机也就是多核，多个CPU共享访问公用RAM。每个多处理机都具有CPU可访问所有全部存储器的性质。有些多处理机具有读取每个存储器速度相同的特性，然后有些机器没有这一特性；前者被称为UMA（统一内存访问）,后者被称为NUMA（非一致内存访问）。

![](https://lonelywatch-1306651324.cos.ap-beijing.myqcloud.com/image-20240914164716126.png)

从UMA开始，对于所有CPU与存储器只连接在一根总线的情况，如果CPU需要读写存储的数据，就必须首先检查总线是否空闲，如果空闲则将所需数据地址放于总线并发出控制信号，等待存储器将所需字放于总线上；否则CPU必须等待直到空闲。从这种角度看可以很好地理解为什么IO被认为是耗时的。

![](https://lonelywatch-1306651324.cos.ap-beijing.myqcloud.com/image-20240914164736397.png)

上述设计对于多CPU的情况性能开销很大，所以为每个CPU添加了Cache，用于缓存存储器数据从而减少直接从总线读取数据的次数。并且Cache通常以32字节或64字节块为基础，CPU读取总线数据时，通常采取预读的方式，将该数据所在的数据块放入Cache中。

如果添加了Cache，就必须考虑CPU对Cache缓存数据的写操作。如果CPU尝试向Cache写入数据，总线检测到了写操作，则会在总线上通知其他告诉缓存，如果其他Cache中有同存储器内容完全相同的版本，就会丢弃该副本，并在写者修改之前，从存储器中取出对应Cache块；如果Cache中有脏副本，则会在处理该写操作前把数据写回，或者直接通过总线传输至总线。

这一套机制就被称为**缓存一致性协议**。除此以外，还有一种设计，即每个CPU除了自身Cache以外，还拥有本地的私有存储器，通过专门的总线访问，并且为了达到利用该私有存储器实现性能优化的目的，编译器往往需要将所有程序的被认为可私有的数据放入私有存储器中，而共享存储器则值用于可写的共享变量。

### 交叉开关

上面提到的单总线多CPU设计对于CPU数量有所限制，如果需要提高则需要使用交叉开关。

![image-20240914165514133](https://lonelywatch-1306651324.cos.ap-beijing.myqcloud.com/image-20240914165514133.png)

### 两级交换

两级交换是一种设计，用于解决交叉开关的问题。在两级交换中，每个CPU与一个交换机相连，交换机与其他交换机相连。交换机的作用是将数据从一个端口传输到另一个端口，而不是将数据从一个端口传输到所有端口。这种设计的优点是可以减少总线的负载，缺点是需要更多的硬件。

### NUMA多处理机

为了进一步提高可支持CPU数量，对UMA的性质做出若干退让，比如所有存储器的访问时间一致。NUMA机器具有对所有CPU可见的单地址空间，但是具有本地存储器与远程存储器两种存储器，访问远程存储器要比访问本地存储器慢，并且需要使用读写指令访问。NUMA根据是否有Cache又可分为NC-NUMA与CC-NUMA,分别为无高速缓存NUMA与高速缓存一致NUMA.

![](https://lonelywatch-1306651324.cos.ap-beijing.myqcloud.com/image-20240914170822622.png)

CC-NUMA的常用实现方式为基于目录的多处理机。其通过维护一个数据库来记录Cache行的位置与状态，如果需要使用该数据则查询该数据库是否可用，其硬件实现要求较高。



### 多处理机OS类型

上面的UMA与NUMA从硬件的组成与设计角度来考虑OS设计，从软件角度来看也有多种演变。


首先是每个CPU可拥有自己的OS数据副本与存储器分配，从而实际上N个CPU以N个独立计算机的形式运行。
这种方式没有进程间的迁移，每个系统调用都只被自身的CPU捕获，并且在Cache情况下很难维持Cache一致性。

第二种方式就是主从多处理机，副本与数据表都存放于某一CPU中，所有的系统调用都重定向于该CPU，若剩余CPU时间，则运行用户进程。

第三种方式就是对称多处理，存储器拥有操作系统的副本，且任何CPU都可运行OS，这种方式消除了主CPU瓶颈，但是需要锁来保证数据一致性。

