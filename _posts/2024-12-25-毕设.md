---
title: 2024-12-25-毕设记录
author: lonelywatch
date: 2024-12-25 21:28 +0800
categories: [ML]
tags: [ML,毕设]
usemath: latex
---


# 2024-12-25

今天做了什么?

1. 具体查询课题的三大方向，包括模型的优化与应用，算子的优化，硬件应用的优化。

2. 阅读了一些相关文献，主要是模型的优化与应用，包括剪枝，量化，权重共享等。

首先利用GPT来达到对概念基础的理解。

## 模型本身

模型的优化这一方面主要有量化，剪枝，权重共享。所谓量化，顾名思义就是对模型所使用的参数类型进行修改，将FP32或者是FP64变为FP16甚至是INT16,INT8,以此来减少模型推理过程中的计算量与硬件要求。这一过程通过对模型参数的缩放实现，需要记录缩放因子，并且在量化完成后可以进一步微调来减少性能损失。

剪枝则是对模型中的冗余参数进行删除，以此来减少模型的大小与计算量。剪枝的方法有很多，主要由结构化剪枝和权重剪枝，结构化剪枝是指对整个层进行剪枝，而权重剪枝则是对单个参数进行剪枝（针对小参数变为0）。

权重共享则是让模型中的不同层共享参数，以此来减少模型的大小与计算量。权重共享的方法有很多，主要有矩阵分解，低秩近似等。Transformer模型中的编解码器都可以使用这种方法。这种方法会限制模型的表达能力，但是会减少模型的大小与计算量。

## 算子优化

接下来是算子方面的优化，算子就是模型中执行具体计算任务的基本组件，比如矩阵乘法，激活函数等。对算子优化，可以加速算子执行，提高能耗比并针对不同硬件充分发挥性能优势。

算子优化包括算法层，软件实现层和硬件利用层，常见的算法曾方法主要由： 算法重构（找一种更高效的算法代替，比如分块矩阵乘法），稀疏优化（跳过0值计算），数据重排（提高数据访问效率）等。

硬件层的话主要利用目标设备的硬件特性，比如nano等设备提供的GPT，利用CUDA进行加速。如果手机设备带有TPU的话，也可以利用TPU来加速张量计算。

再一个就是 算子融合，这主要是减少内存占用和功耗，通过将多个算子合并为更少量的算子来减少中间结果，以此来降低内存开销和访问延迟。 通常而言，还可以以数据复用，数据缓冲对齐等为目标。 

## 知识蒸馏
