---
title: 2024-12-24-毕设记录
author: lonelywatch
date: 2024-12-24 21:28 +0800
categories: [ML]
tags: [ML,毕设]
usemath: latex
---

# 2024-12-24

老实说当时看着这毕设的板子我好像都有就选了，而且刚好还是AIGC在端侧的优化应用，所以我就选了这个。

今天做了什么？

1. 查询课题背景，主要是模型的优化与应用。

2. 配置环境，微调了预训练后了的GPT-2, 然后进行测试。

3. 利用得到的参数文件，使用TensorRT与ONNX进行量化。

4. 重新配置Jetson Nano环境,测试量化后的模型，重新配置了树莓派4B的环境。

老实说，当时不应该买Jetson Nano的，应该直接买TX2的（题目上写的就要用TX2,不过我现在只有nano），我看了下现在的价格好像就差了个两三百，性能差了两三倍。我都不知道当时犯什么蠢。

树莓派性能比Jetson Nano更差，毕竟nano还带了个几百兆赫兹的Maxwell架构的GPU，还可以用用几年前的CUDA，树莓派连GPU都没有。我有点难以想象后续是否真的可以在树莓派上运行并取得较好的成果。

最后回到最根本的优化技术。定性来说，主要分为模型本身的优化（剪枝，权重共享，量化等以此来降低对硬件的要求）,算子本身的优化，硬件应用的优化（使得硬件资源利用率更高），以此来达到能效比更高，性能更好的目的。

这确实是一个比较有前景的方向，我是这么认为的。

剪枝与量化这些技术很多大框架都有提供，比如TensorRT,ONNX等，但是具体的实现还是需要根据硬件的特性来进行调整，这里就需要对硬件有一定的了解。

## 模型微调

目前手上没有很好的训练卡，并且课题针对模型本身的优化以及硬件应用优化，也没有必要从头训练，所以选择了微调。

这里使用Pytorch和Huggingface的transformers库，使用GPT-2模型进行微调，微调所使用的数据集为WikiText-2。

训练过程请参考[这里](https://www.kaggle.com/code/suraj520/pytorch-train-gpt2-and-generate-text-from-it),具体内容不再赘述。

最后得到了对应模型的参数文件。

需要注意所使用包的版本以及对应依赖尽量与对应的硬件环境相匹配，以免后续出现不必要的问题。

## Jetson Nano 配置

1. 准备一张64G大小的内存卡与读卡器。

2. 使用DC 5V 4A的电源供电（需要将J48跳接）,使用micro usb连接主机进行串口通信，如果后续操作正常，则会产生虚拟以太网，一般NANO为192.168.55.1。

3. 前往Nvidia官网下载Jetson Nano的[镜像](https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#setup)，使用Etcher烧录到内存卡。

4. 填入内存卡，开机并使用串口(Baud 115200)进行配置。

5. 使用网线连接主机，并为nano配置静态IP，方便后续SSH连接。具体方法为修改`/etc/network/interfaces`文件，添加如下内容：

   ```shell
   auto eth0
   iface eth0 inet static
   address xx.xx.xx.xx
   netmask xx.xx.xx.xx
   gateway xx.xx.xx.xx
    ```
    随后重启网络服务`sudo service networking restart`。

6. 安装miniforge,并安装mamba代替conda(mamba据传比conda更快)。

7. 前往Nvidia官网下载Pytorch的whl文件，使用mamba安装（请注意Nano提供的GPU核心版本为sm52，所以请下载Pytorch1.10.x版本）。安装TensorRT，ONNX等优化包。

注意：Nvidia提供的镜像包是JetPack 4.6.1左右，Ubuntu为18.04,通过APT包管理器安装的fish可能不与miniconda兼容，但是还是能用，只是会出现一些报错。

## 树莓派4B配置

1. 准备一张64G大小的内存卡与读卡器。

2. 使用 Pi Image烧录Aarch64的镜像到内存卡，并设置ssh。

3. 使用OTG USB线供电，使用串口进行通信（JTAG上的3个针脚，使用TTL转USB串口线进行通信）。

4. 配置静态IP方便SSH连接，方法如上。

5. 安装miniforge,并安装mamba代替conda，配置Pytorch与对应的Tensorflow（很久以前这玩意还是挺流行的）。

6. 安装TensorRT,ONNX等优化包。**配置SWAP分区**。

这里可以安装fish和nvim等开发工具。

## 代理配置

针对硬件环境下的国外访问问题，可以使用代理，在SHELL中设置对应的代理环境变量即可,比如在fish中：
    
    ```shell
    set -x http_proxy http://192.168.137.100:10809
    set -x https_proxy http://192.168.137.100:10809
    ```
对应的代理服务器地址与端口号请根据实际情况进行设置。

fishd的配置文件为`~/.config/fish/config.fish`,bash的配置文件通常为`~/.bashrc`。

## 结束的想法

前两天不由得有点想摆烂，果然目标不在眼前就坚持不下去。来那里弹琴的人变少了，或许都去M204了吧。真是任重而道远。